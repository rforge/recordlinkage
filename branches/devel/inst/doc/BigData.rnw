% \VignetteIndexEntry{Classes for record linkage of big data sets}

<<echo=false,results=hide>>=
options(width=50)
@

\documentclass[a4paper]{article}

%\usepackage[ansinew]{inputenc}
%\usepackage[ngerman]{babel}

\begin{document}

\title{Classes for record linkage of big data sets}
\author{Andreas Borg, Murat Sariyar}

\maketitle

As of version 0.3, the package RecordLinkage includes extensions to overcome
the problem of high memory consumption which arises when processing a large
number of record pairs (>= 1 million). This is achieved by a concept where
the whole set of record pairs is not created at once, but block-wise during
classification. In addition, an embedded SQLite database is used through
package RSQLite to perform blocking, application of phonetic codes or string
metrics and creation of comparison patterns. This allows to make use of the
efficient data structures (e.g. indexing) implemented in the SQLite engine.

In order to facilitate a tidyer design, S4 classes and methods were used to
implement the extensions. In favor of backward compatibility and development
time, plans of a complete transition to S4 were dismissed. Nevertheless, the
existing functions were joined with their new counterparts, resulting in
methods which dispatch on the new S4 as well as on the existing S3 classes.
This approach combines two advantages: First, existing code using the package
still works, second, the new classes and methods offer (nearly) the same
interface, i.e. the necessary function calls for a linkage task differ only
slightly.

(TODO: exception: getPairs redesigned. should be okay because it is mainly intended
for interactive use and output of results)

\section{Defining data and comparison parameters}

The existing S3 class \texttt{"RecLinkData"} is supplemented by the S4 classes
\texttt{"RLBigDataLinkage"} and \texttt{"RLBigDataDedup"} for linking two datasets
and deduplication of one dataset respectively. Both share the common abstract (virtual)
superclass \texttt{"RLBigData"}.

<<>>=
library(RecordLinkage)

showClass("RLBigData")
showClass("RLBigDataDedup")
showClass("RLBigDataLinkage")
@

For the two non-virtual classes constructor functions exist which correspond
to \texttt{compare.dedup} and \texttt{compare.linkage} for the S3 classes.
<<>>=
# deduplicate dataset with two blocking iterations and string comparison
data(RLdata500)
data(RLdata10000)
rpairs1 <- RLBigDataDedup(RLdata500, identity = identity.RLdata500, blockfld = list(1,3),
  strcmp = 1:4)

# link two datasets with phonetic code, exclude lname_c2
s1 <- 471:500
s2 <- sample(1:10000, 300)
identity2 <- c(identity.RLdata500[s1], rep(NaN, length(s2)))
dataset <- rbind(RLdata500[s1,], RLdata10000[s2,])
rpairs2 <- RLBigDataLinkage(RLdata500, dataset, identity1 = identity.RLdata500,
  identity2 = identity2, phonetic = 1:4, exclude = "lname_c2")
@

Comparison patterns are created on demand and blockwise, facilitated by
the internal functions:
\begin{description}
  \item[begin] Construct SQL statement to execute blocking, phonetic code,
    string comparison and building comparison patterns; send query to underlying
    database.
  \item[nextPairs] Fetch next block of patterns.
  \item[clear] Clear result set after comparison patterns have been fetched or
    to cancel.
\end{description}

<<>>=
rpairs1 <- begin(rpairs1)
nextPairs(rpairs1, 10)
clear(rpairs1)
@

These functions are usually not directly executed by the user, they
form part of the backend of the classification functions.

\section{Supervised classification}

The existing function \texttt{classifySupv} was transformed to a S4 method
which handles the old S3 object (\texttt{"RecLinkData"}) as well as the new 
classes.

<<>>=
train <- getMinimalTrain(compare.dedup(RLdata500, identity = identity.RLdata500,
  blockfld = list(1,3)))
rpairs1 <- RLBigDataDedup(RLdata500, identity = identity.RLdata500)
classif <- trainSupv(train, "rpart", minsplit=2)
result <- classifySupv(classif, rpairs1)
# first two arguments can be switched:
result <- classifySupv(rpairs1, classif)
@

The result is an object of class \texttt{"RLResult"} which holds the indices
of links and optionally possible links.
<<>>=
showClass("RLResult")
@
A contingency table can be viewed via \texttt{getTable}:
<<>>=
getTable(result)
@

(Anm.: Objekt muss evtl. noch weiter ausgebaut und ergänzende Methoden geschrieben 
werden)

\section{Weight-based classification}

<<>>=
result <- epiClassify(rpairs2,0.6)
getTable(result)
@

(Implementierung von em arbeitet im Moment mit einer Klasse EMWeights, die
Gewichte und das zugehörige RLBigData-Objekt enthält. Von der Struktur her
wäre es vielleicht umgekehrt sinnvoller: Gewichte sind ein Attribut eines 
Datenobjekts. Nachteil der letzteren Lösung: Dieses Attribut kann leer sein
(wenn keine Gewichte berechnet wurden), seine Existenz muss also abgefragt 
werden - bei der eigenen Klasse ist über die Methodensignatur gesichert,
dass die Klassifikationsfunktion nur für Objekte mit Gewichten aufgerufen wird.

Oder: Klassifierungsfunktion prüft, ob Gewichte vorhanden sind und erstellt sie,
falls nicht -> Nachteil: Wenn man aus Versehen die Methode auf einem Objekt ohne
Gewichte aufruft, wird die zeitintensive EM-Schätzung unnötig aufgerufen,
statt durch Fehlermeldung das Versehen anzuzeigen).

TODO: possible links
)

<<>>=
rpairs3 <- RLBigDataDedup(RLdata500, identity.RLdata500, blockfld=1)
W <- emWeights(rpairs3)
result <- emClassify(W)
getTable(result)

W <- emWeights(rpairs3)
result <- emClassify(W, my = 0.005)
getTable(result)

@

\end{document}






