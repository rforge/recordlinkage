% \VignetteIndexEntry{Classes for record linkage of big data sets}

<<echo=false,results=hide>>=
options(width=50)
@

\documentclass[a4paper]{article}

%\usepackage[ansinew]{inputenc}
%\usepackage[ngerman]{babel}

\begin{document}

\title{Classes for record linkage of big data sets}
\author{Andreas Borg, Murat Sariyar}

\maketitle

As of version 0.3, the package RecordLinkage includes extensions to overcome
the problem of high memory consumption which arises when processing a large
number of records (ca.\ $>=1000$ without blocking, $>=10000$ with one blocking
variable). This is achieved by a concept where
the whole set of record pairs is not created at once, but block-wise during
classification. In addition, an embedded SQLite database is used through
package RSQLite to perform blocking, application of phonetic codes or string
metrics and creation of comparison patterns. This allows to make use of the
efficient data structures (e.g. indexing) implemented in the SQLite engine.

In order to facilitate a tidyer design, S4 classes and methods were used to
implement the extensions. In favor of backward compatibility and development
time, plans of a complete transition to S4 were dismissed. Nevertheless, the
existing functions were joined with their new counterparts, resulting in
methods which dispatch on the new S4 as well as on the existing S3 classes.
This approach combines two advantages: First, existing code using the package
still works, second, the new classes and methods offer (nearly) the same
interface, i.e. the necessary function calls for a linkage task differ only
slightly. An exception is \texttt{getPairs}, whose arguments differ from the
exisiting version (see man page).

\section{Defining data and comparison parameters}

The existing S3 class \texttt{"RecLinkData"} is supplemented by the S4 classes
\texttt{"RLBigDataLinkage"} and \texttt{"RLBigDataDedup"} for linking two datasets
and deduplication of one dataset respectively. Both share the common abstract
superclass \texttt{"RLBigData"}.

<<>>=
library(RecordLinkage)

showClass("RLBigData")
showClass("RLBigDataDedup")
showClass("RLBigDataLinkage")
@

For the two non-virtual classes constructor functions, \texttt{RLBigDataDedup}
and \texttt{RLBigDataLinkage}, exist which correspond
to \texttt{compare.dedup} and \texttt{compare.linkage} for the S3 classes and
share most of their arguments. In contrast to the latter, these functions do
not create the whole set of comparison patterns but only instantiates an object
that holds all the information necessary to construct these pairs on demand.

The following example shows the basic usage of the constructors, for details
consult their documentation.
<<>>=
# deduplicate dataset with two blocking iterations and string comparison
data(RLdata500)
data(RLdata10000)
rpairs1 <- RLBigDataDedup(RLdata500, identity = identity.RLdata500, blockfld = list(1,3),
  strcmp = 1:4)

# link two datasets with phonetic code, exclude lname_c2
s1 <- 471:500
s2 <- sample(1:10000, 300)
identity2 <- c(identity.RLdata500[s1], rep(NaN, length(s2)))
dataset <- rbind(RLdata500[s1,], RLdata10000[s2,])
rpairs2 <- RLBigDataLinkage(RLdata500, dataset, identity1 = identity.RLdata500,
  identity2 = identity2, phonetic = 1:4, exclude = "lname_c2")
@

In order to create comparison patterns, the following backend functions exist,
which are usually not directly executed by the user:
\begin{description}
  \item[begin] Constructs an SQL statement to execute blocking, phonetic code,
    string comparison and building comparison patterns and sends this query to
    the underlying SQLite database.
  \item[nextPairs] Fetches a block of patterns after the query has been send.
  \item[clear] Clears the result set after comparison patterns have been fetched.
\end{description}

<<>>=
rpairs1 <- begin(rpairs1)
nextPairs(rpairs1, 10)
clear(rpairs1)
@


\section{Supervised classification}

The existing function \texttt{classifySupv} was transformed to a S4 method
which handles the old S3 object (\texttt{"RecLinkData"}) as well as the new 
classes.  However, at the moment a classificator can only be trained with
an object of class \texttt{"RecLinkResult"}, for which comparison patterns
are stored in the R object.

<<>>=
train <- getMinimalTrain(compare.dedup(RLdata500, identity = identity.RLdata500,
  blockfld = list(1,3)))
rpairs1 <- RLBigDataDedup(RLdata500, identity = identity.RLdata500)
classif <- trainSupv(train, "rpart", minsplit=2)
result <- classifySupv(classif, rpairs1)
@

The result is an object of class \texttt{"RLResult"} which holds the indices
of links and optionally possible links.
<<>>=
showClass("RLResult")
@
A contingency table can be viewed via \texttt{getTable}, various error measures
are calculated by \texttt{getErrorMeasures}.
<<>>=
getTable(result)
getErrorMeasures(result)
@


\section{Weight-based classification}

As with \texttt{"RecLinkData"} objects, weight-based classification with
\texttt{"RLBigData*"} classes includes weight calculation and classification
based on one or two thresholds, dividing links, non-links and, if desired,
possible links. The following example applies classification with
Epilink (see documentation of \texttt{epiWeights} for details):
<<>>=
rpairs1 <- epiWeights(rpairs1)
result <- epiClassify(rpairs1, 0.5)
getTable(result)
@


 By default, the weights for each individual record pair are
stored in the associated database, which speeds up subsequent classification
significantly. If the resulting disk usage is an issue, this behaviuor can be
changed;
\begin{itemize}
  \item in the case of weight calculation with an EM algorithm by calling
    \texttt{emWeights} with argument \texttt{save.weights = FALSE},
      which results in only $2^{\textrm{number of attributes}}$
      per-pattern weights being stored;
  \item in the case of Epilink weights, by calling \texttt{epiWeights}
    directly; the weights will be calculated on-the-fly.
\end{itemize}




\section{Evaluation and results}

In addition to \texttt{getTable} and \texttt{getErrorMeasures},
\texttt{getPairs}, which was redesigned as a versatile S4 method, is an
important tool to inspect data and linkage results. For example, the following
code extracts all links with weights greater or equal than 0.7 from the result
set obtained in the last example:

<<>>=
getPairs(result, min.weight=0.7, filter.link="link")
@

A frequent use case is to inspect misclassifed record pairs; for this
purpose two shortcuts are included that call \texttt{getPairs} with
appropriate arguments:

<<>>=
getFalsePos(result)
getFalseNeg(result)

@

\end{document}






